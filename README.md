# Transformer DDoS Detector

A clean, maintainable Python project that trains a **Transformer-based neural network** to classify DDoS network attacks using the CIC-DDoS2019 and CIC-IDS2017 datasets.

---

## Project Structure

```
Transformer DDoS Detector/
├── data/
│   ├── CIC-DDoS2019/          # Raw CSVs  (DrDoS_LDAP, MSSQL, NTP, …)
│   ├── CIC-IDS2017/           # Raw CSVs  (add files here when available)
│   └── processed/             # Generated by notebooks (parquet, npy, JSON)
│
├── model/                     # Saved model artifacts (generated by notebook 03)
│   ├── transformer_ddos.pt    # Model weights + hyperparameters
│   ├── scaler.pkl             # Fitted MinMaxScaler
│   ├── label_encoder.pkl      # Fitted LabelBinarizer
│   └── selected_features.json # Names of the 20 selected features
│
├── notebooks/
│   ├── 01_data_preprocessing.ipynb  # Cleaning + exploration
│   ├── 02_feature_selection.ipynb   # Train/test split + RF feature selection
│   └── 03_model_training.ipynb      # Transformer training + full evaluation
│
├── utils/
│   ├── __init__.py
│   ├── data_loader.py        # CSV loading helpers
│   ├── preprocessing.py      # Cleaning, scaling, label encoding
│   ├── feature_selection.py  # Random Forest feature selection
│   ├── visualization.py      # Reusable chart functions
│   └── model_utils.py        # Transformer model, train/eval loops, save/load
│
├── requirements.txt
└── README.md
```

---

## Pipeline Overview

| Notebook                | Stage                        | Output                                               |
| ----------------------- | ---------------------------- | ---------------------------------------------------- |
| `01_data_preprocessing` | Load → Clean → Encode labels | `cleaned_dataset.parquet`                            |
| `02_feature_selection`  | Split → Scale → RF selection | `X_*_sc.npy`, `scaler.pkl`, `selected_features.json` |
| `03_model_training`     | Train → Evaluate → Save      | `model/transformer_ddos.pt`                          |

### Data Leakage Prevention

| Operation                | Where it is fitted  |
| ------------------------ | ------------------- |
| `MinMaxScaler`           | Training split only |
| `LabelBinarizer`         | Training split only |
| `RandomForestClassifier` | Training split only |
| `TransformerClassifier`  | Training split only |

---

## Setup

```bash
# 1. Create and activate a virtual environment
python -m venv .venv
.venv\Scripts\activate        # Windows
# source .venv/bin/activate   # Linux / macOS

# 2. Install dependencies
pip install -r requirements.txt

# 3. Register the kernel
python -m ipykernel install --user --name ddos-detector

# 4. Start Jupyter
jupyter notebook
```

---

## Running the Notebooks

Run the notebooks **in order**:

1. **`01_data_preprocessing.ipynb`** — Loads all CSV files, removes duplicates/NaN/Inf, shows label distributions, saves cleaned data.
2. **`02_feature_selection.ipynb`** — Performs the train/test split, fits the scaler and label encoder on training data, runs Random Forest to select top 20 features, saves all artifacts.
3. **`03_model_training.ipynb`** — Trains the Transformer model, plots training history and evaluation metrics (accuracy, precision, recall, F1, confusion matrix, ROC curves), saves the final model.

> **Quick development mode:** Set `SAMPLE_FRAC = 0.05` at the top of notebook 01 to run on 5% of data for fast iteration.

---

## Transformer Architecture

```
Input (batch, 20 features)
 └─ Linear projection  →  d_model = 128
 └─ TransformerEncoder (2 layers × 4 heads, FF dim = 256, dropout = 0.1)
 └─ Global squeeze (seq_len = 1)
 └─ Dropout → Linear(128→64) → GELU → Dropout → Linear(64→n_classes)
 └─ Logits (BCEWithLogitsLoss during training)
```

---

## Evaluation Metrics (Notebook 03)

- **Accuracy** — overall correct predictions
- **Precision / Recall / F1** — per class + macro / weighted averages
- **Confusion matrix** — raw counts and row-normalized (recall per class)
- **Metrics bar chart** — grouped bars per class
- **Radar chart** — spider chart comparing metrics across classes
- **ROC curves** — one-vs-rest AUC per class
